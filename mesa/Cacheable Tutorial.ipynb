{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7145083-bb0e-48ce-9f77-46d8b6526efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import mesa\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# import cacheable model wrapper\n",
    "from cacheable_model import CacheableModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcbf68f-dadb-4f60-9dab-f96c54a50d03",
   "metadata": {},
   "source": [
    "The following code is to clear the default directory which the cached fiels are saved to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc579d94-9a2b-4e7c-9f54-f7b49244f535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory output_dir and its contents have been deleted.\n"
     ]
    }
   ],
   "source": [
    "directory = \"output_dir\"\n",
    "\n",
    "def delete_directory(directory_path):\n",
    "    shutil.rmtree(directory_path)\n",
    "    print(f\"Directory {directory_path} and its contents have been deleted.\")\n",
    "\n",
    "try:\n",
    "    delete_directory(directory)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd4824-1d63-449f-a905-0d20fe221551",
   "metadata": {},
   "source": [
    "Define the Boltzmann Wealth Model. I chose to reimplement it here so that I can modify the attributes and experiment with the results more easily. The code is taken from the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52148277-e575-4873-b4fc-32947b24265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gini(model):\n",
    "    agent_wealths = [agent.wealth for agent in model.schedule.agents]\n",
    "    x = sorted(agent_wealths)\n",
    "    N = model.num_agents\n",
    "    B = sum(xi * (N - i) for i, xi in enumerate(x)) / (N * sum(x))\n",
    "    return 1 + (1 / N) - 2 * B\n",
    "\n",
    "\n",
    "class MoneyAgent(mesa.Agent):\n",
    "    \"\"\"An agent with fixed initial wealth.\"\"\"\n",
    "\n",
    "    def __init__(self, unique_id, model):\n",
    "        super().__init__(unique_id, model)\n",
    "        self.wealth = 1\n",
    "\n",
    "    def move(self):\n",
    "        possible_steps = self.model.grid.get_neighborhood(\n",
    "            self.pos, moore=True, include_center=False\n",
    "        )\n",
    "        new_position = self.random.choice(possible_steps)\n",
    "        self.model.grid.move_agent(self, new_position)\n",
    "\n",
    "    def give_money(self):\n",
    "        cellmates = self.model.grid.get_cell_list_contents([self.pos])\n",
    "        cellmates.pop(\n",
    "            cellmates.index(self)\n",
    "        )  # Ensure agent is not giving money to itself\n",
    "        if len(cellmates) > 1:\n",
    "            other = self.random.choice(cellmates)\n",
    "            other.wealth += 1\n",
    "            self.wealth -= 1\n",
    "            if other == self:\n",
    "                print(\"I JUST GAVE MONEY TO MYSELF HEHEHE!\")\n",
    "\n",
    "    def step(self):\n",
    "        self.move()\n",
    "        if self.wealth > 0:\n",
    "            self.give_money()\n",
    "\n",
    "\n",
    "class MoneyModel(mesa.Model):\n",
    "    \"\"\"A model with some number of agents.\"\"\"\n",
    "\n",
    "    def __init__(self, N, width, height):\n",
    "        super().__init__()\n",
    "        self.num_agents = N\n",
    "        self.grid = mesa.space.MultiGrid(width, height, True)\n",
    "        self.schedule = mesa.time.RandomActivation(self)\n",
    "\n",
    "        # Create agents\n",
    "        for i in range(self.num_agents):\n",
    "            a = MoneyAgent(i, self)\n",
    "            self.schedule.add(a)\n",
    "            # Add the agent to a random grid cell\n",
    "            x = self.random.randrange(self.grid.width)\n",
    "            y = self.random.randrange(self.grid.height)\n",
    "            self.grid.place_agent(a, (x, y))\n",
    "\n",
    "        self.datacollector = mesa.DataCollector(\n",
    "            model_reporters={\"Gini\": compute_gini}, agent_reporters={\"Wealth\": \"wealth\"}\n",
    "        )\n",
    "\n",
    "    def step(self):\n",
    "        self.datacollector.collect(self)\n",
    "        self.schedule.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3d50a-9060-47fb-a92c-979e6f3fa12c",
   "metadata": {},
   "source": [
    "Instantiate the base model without caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4604c813-7bc7-4b99-a44e-28f613013676",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MoneyModel(100, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32bb6f5d-4726-44ed-8480-79d37d0cc7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_function(model_vars): # condition to cache the results specifically\n",
    "        return model_vars.get('Gini', 0)[-1] > 0.7\n",
    "    \n",
    "number_of_steps = 1000\n",
    "\n",
    "cacheable_model = CacheableModel(model, directory, number_of_steps, 100, condition_function=condition_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53fde31f-950f-4549-8b59-70f1a64c256b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition met. Appended special results for step 80 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 245 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 246 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 247 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 248 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 249 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 254 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 257 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 258 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 259 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 260 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 261 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 331 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 333 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 334 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 336 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 337 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 338 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 428 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 429 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 430 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 431 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 432 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 433 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 436 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 437 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 444 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 445 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 446 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 447 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 448 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 449 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 479 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 489 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 490 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 492 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 494 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 495 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 502 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 503 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 568 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 569 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 571 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 572 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 583 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 607 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 608 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 610 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 612 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 663 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 664 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 665 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 666 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 667 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 780 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 809 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 810 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 811 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 812 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 813 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 814 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 815 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 816 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 817 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 818 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 819 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 820 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 821 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 823 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 908 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 919 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 920 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 922 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 923 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 934 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 935 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 936 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 938 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 939 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 961 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 990 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 991 to output_dir/special_results.parquet\n",
      "Condition met. Appended special results for step 995 to output_dir/special_results.parquet\n"
     ]
    }
   ],
   "source": [
    "for i in range(number_of_steps):\n",
    "    cacheable_model.model.step()\n",
    "    cacheable_model.get_grid_dataframe(\"test\")\n",
    "    cacheable_model.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d17fd0-7daa-4791-9fa5-485d01598ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       Gini\n",
       " 0    0.0000\n",
       " 1    0.2112\n",
       " 2    0.3842\n",
       " 3    0.5126\n",
       " 4    0.5110\n",
       " ..      ...\n",
       " 995  0.6900\n",
       " 996  0.6712\n",
       " 997  0.6400\n",
       " 998  0.6346\n",
       " 999  0.5856\n",
       " \n",
       " [1000 rows x 1 columns],\n",
       "               Wealth\n",
       " Step AgentID        \n",
       " 0    0             1\n",
       "      1             1\n",
       "      2             1\n",
       "      3             1\n",
       "      4             1\n",
       " ...              ...\n",
       " 999  95            0\n",
       "      96            0\n",
       "      97            1\n",
       "      98            0\n",
       "      99            3\n",
       " \n",
       " [100000 rows x 1 columns])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df, agent_df = cacheable_model.combine_dataframes()\n",
    "model_df, agent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15dcaaea-9c4d-49b3-ab5c-28664cf66e68",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'width'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'width'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcacheable_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_grid_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcacheable_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/wsl/github/mesa-forked/mesa/cacheable_model.py:129\u001b[0m, in \u001b[0;36mCacheableModel.read_grid_state\u001b[0;34m(self, filename, model)\u001b[0m\n\u001b[1;32m    126\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(filename)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Extract grid dimensions from the file\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwidth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    130\u001b[0m height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Initialize the grid\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'width'"
     ]
    }
   ],
   "source": [
    "cacheable_model.read_grid_state(\"test\", cacheable_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d910bce8-5659-4c5b-83eb-6d83ec8355e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Any\n",
    "\n",
    "def read_grid_state(filename='grid_cache.parquet', model: Any = None) -> Any:\n",
    "    \"\"\"Read the grid state from a Parquet file and reconstruct the grid with agents.\"\"\"\n",
    "    # Load DataFrame from Parquet\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    # Extract grid dimensions from the file\n",
    "    width = int(df['width'].iloc[0])\n",
    "    height = int(df['height'].iloc[0])\n",
    "    \n",
    "    # Initialize the grid\n",
    "    grid = Grid(width=width, height=height)  # Adjust as needed for your grid class\n",
    "\n",
    "    # Reconstruct agents and place them in the grid\n",
    "    agents = df[['pos_x', 'pos_y', 'wealth', 'unique_id']]\n",
    "    for _, row in agents.iterrows():\n",
    "        pos_x = int(row['pos_x'])\n",
    "        pos_y = int(row['pos_y'])\n",
    "        unique_id = int(row['unique_id'])\n",
    "        wealth = float(row['wealth'])\n",
    "        \n",
    "        # Create agent instance (adjust based on how you create agents)\n",
    "        agent = Agent(unique_id=unique_id, model=model)\n",
    "        agent.pos = (pos_x, pos_y)\n",
    "        agent.wealth = wealth\n",
    "\n",
    "        # Place agent in the grid\n",
    "        grid._grid[pos_x][pos_y] = grid._grid[pos_x][pos_y] or []\n",
    "        grid._grid[pos_x][pos_y].append(agent)\n",
    "\n",
    "    return grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb34d38-8be5-44ad-b584-3038ea55d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading a grid from a Parquet file\n",
    "  # Your model instance, or a placeholder if required\n",
    "grid = read_grid_state('test', model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2c4e8d-7bc6-484b-bedf-86e58d53ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"test\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c8640-38ec-4762-8cda-1681549ecad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
